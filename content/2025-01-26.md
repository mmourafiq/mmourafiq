---
layout: list
---

 - [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948)
 - [Exploring and Mitigating Adversarial Manipulation of Voting-Based Leaderboards](https://arxiv.org/abs/2501.07493)
 - [On DeepSeek's r1](https://thezvi.substack.com/p/on-deepseeks-r1)
 - [Why o3-mini *had* to be free: the coming DeepSeek R1, 2.0 Flash, and Sky-T1 Price War](https://www.latent.space/p/reasoning-price-war)
 - [R1+Sonnet set SOTA on aiderâ€™s polyglot benchmark ](https://aider.chat/2025/01/24/r1-sonnet.html)
 - [AI Slop, Suspicion, and Writing Back](https://benjamincongdon.me/blog/2025/01/25/AI-Slop-Suspicion-and-Writing-Back/)
 - [Explainer: What's R1 & Everything Else?](https://timkellogg.me/blog/2025/01/25/r1)
 - [7B Model and 8K Examples: Emerging Reasoning with Reinforcement Learning is Both Effective and Efficient](https://hkust-nlp.notion.site/simplerl-reason)
- [OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework (70B+ PPO Full Tuning & Iterative DPO & LoRA & RingAttention & RFT)](https://github.com/OpenRLHF/OpenRLHF)
- [Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models](https://arxiv.org/abs/2408.00724v2)
