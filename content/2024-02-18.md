---
layout: list
---

 - [Representation Engineering Mistral-7B an Acid Trip](https://vgel.me/posts/representation-engineering/)
 - [ Minimal, clean, code for the Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization. ](https://github.com/karpathy/minbpe)
 - [Towards Monosemanticity: Decomposing Language Models With Dictionary Learning](https://transformer-circuits.pub/2023/monosemantic-features)
 - [I made a transformer by hand (no training!)](https://vgel.me/posts/handmade-transformer/)
 - [Why we always put log() before the joint pdf when we use MLE(Maximum likelihood Estimation)?](https://stats.stackexchange.com/questions/70972/why-we-always-put-log-before-the-joint-pdf-when-we-use-mlemaximum-likelihood)
 - [Why is everything based on likelihoods even though likelihoods are so small?](https://stats.stackexchange.com/questions/639548/why-is-everything-based-on-likelihoods-even-though-likelihoods-are-so-small)
 - [AI #51: Altman's Ambition](https://thezvi.substack.com/p/ai-51-altmans-ambition)
